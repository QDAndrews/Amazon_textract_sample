#Step 1 
pip install boto3
wget https://aws-tc-largeobjects.s3.amazonaws.com/DEV-AWS-MO-MachineLearning/downloads/exercise-source.zip
unzip exercise-source.zip

# Step 2 
cd exercise-textract
python3 main.py

# Step 3 replace main.py code 

import glob
import boto3
import json
import csv
import sys

csv_array = []
client = boto3.client('textract')
for filename in glob.glob('raw_images/*.jpg'):
    csv_row = {}
    print(f"Processing: {filename}")
    with open(filename, 'rb') as fd:
        file_bytes = fd.read()

    response = client.analyze_document(
        Document={'Bytes': file_bytes},
        FeatureTypes=["QUERIES"],
        QueriesConfig={
            'Queries': [
                {'Text': 'What is the response id', 'Alias': 'ResponseId'},
                {'Text': 'What are the notes?', 'Alias': 'Notes'},
            ]
        }
    )

    # uncomment this to see the format of the reponse
    # print(json.dumps(response, indent=2))

    for block in response["Blocks"]:
        if block["BlockType"] == "QUERY":
            query_alias = block["Query"]["Alias"]
            answer_id = next(rel["Ids"] for rel in block["Relationships"] if rel['Type'] == "ANSWER")[0]
            answer_text = next(b for b in response["Blocks"] if b["Id"] == answer_id)["Text"]
            csv_row[query_alias] = answer_text
    csv_array.append(csv_row)

writer = csv.DictWriter(sys.stdout, fieldnames=["ResponseId", "Notes"], dialect='excel')
writer.writeheader()
for row in csv_array:
    writer.writerow(row)

# Step 4 return to terminal and execute code 
python3 main.py
